When data are noisy, it’s our job as data scientists to listen 
for signals so we can relay it to someone who can decide how to 
act. To amp up how loudly hidden signals speak over the noise 
of big and/or volatile data, we can deploy smoothing algorithms, 
which though traditionally used in time-series analyses, also 
come into their own when applied on other sequential data. 
Smoothing algorithms are either global or local because they take 
data and filter out noise across the entire, global series, or 
over a smaller, local series by summarizing a local or global 
domain of Y, resulting in an estimation of the underlying data 
called a smooth. The specific smoother you use depends on your 
analysis’ goal and data quirks, because as we’ll see below, 
there are trade-offs to consider. Below are a few options, along 
with their intuition, limitations, and formula so you can rapidly 
evaluate when and why to use one over the other.